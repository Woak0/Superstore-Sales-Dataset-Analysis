{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47261175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after conversion:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9800 entries, 0 to 9799\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Row_ID         9800 non-null   int64  \n",
      " 1   Order_ID       9800 non-null   object \n",
      " 2   Order_Date     9800 non-null   object \n",
      " 3   Ship_Date      9800 non-null   object \n",
      " 4   Ship_Mode      9800 non-null   object \n",
      " 5   Customer_ID    9800 non-null   object \n",
      " 6   Customer_Name  9800 non-null   object \n",
      " 7   Segment        9800 non-null   object \n",
      " 8   Country        9800 non-null   object \n",
      " 9   City           9800 non-null   object \n",
      " 10  State          9800 non-null   object \n",
      " 11  Postal_Code    9789 non-null   float64\n",
      " 12  Region         9800 non-null   object \n",
      " 13  Product_ID     9800 non-null   object \n",
      " 14  Category       9800 non-null   object \n",
      " 15  Sub-Category   9800 non-null   object \n",
      " 16  Product_Name   9800 non-null   object \n",
      " 17  Sales          9800 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(15)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Loads the dataset (note: If the csv is not stored in the same file path as this notebook, adjust the path in the code below to match the correct csv filepath.)\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Renames the columns to be more Power BI friendly (e.g., removes spaces or special characters)\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "print(\"Data types after conversion:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc3d1aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows:\n",
      "   Row_ID        Order_ID  Order_Date   Ship_Date       Ship_Mode Customer_ID  \\\n",
      "0       1  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
      "1       2  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
      "2       3  CA-2017-138688  12/06/2017  16/06/2017    Second Class    DV-13045   \n",
      "3       4  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
      "4       5  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
      "\n",
      "     Customer_Name    Segment        Country             City       State  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
      "1      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  California   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
      "\n",
      "   Postal_Code Region       Product_ID         Category Sub-Category  \\\n",
      "0      42420.0  South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1      42420.0  South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2      90036.0   West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3      33311.0  South  FUR-TA-10000577        Furniture       Tables   \n",
      "4      33311.0  South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product_Name     Sales  \n",
      "0                  Bush Somerset Collection Bookcase  261.9600  \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400  \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200  \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775  \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680  \n",
      "\n",
      "==================================================\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9800 entries, 0 to 9799\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Row_ID         9800 non-null   int64  \n",
      " 1   Order_ID       9800 non-null   object \n",
      " 2   Order_Date     9800 non-null   object \n",
      " 3   Ship_Date      9800 non-null   object \n",
      " 4   Ship_Mode      9800 non-null   object \n",
      " 5   Customer_ID    9800 non-null   object \n",
      " 6   Customer_Name  9800 non-null   object \n",
      " 7   Segment        9800 non-null   object \n",
      " 8   Country        9800 non-null   object \n",
      " 9   City           9800 non-null   object \n",
      " 10  State          9800 non-null   object \n",
      " 11  Postal_Code    9789 non-null   float64\n",
      " 12  Region         9800 non-null   object \n",
      " 13  Product_ID     9800 non-null   object \n",
      " 14  Category       9800 non-null   object \n",
      " 15  Sub-Category   9800 non-null   object \n",
      " 16  Product_Name   9800 non-null   object \n",
      " 17  Sales          9800 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(15)\n",
      "memory usage: 1.3+ MB\n",
      "\n",
      "==================================================\n",
      "\n",
      "Missing Values per Column:\n",
      "Row_ID            0\n",
      "Order_ID          0\n",
      "Order_Date        0\n",
      "Ship_Date         0\n",
      "Ship_Mode         0\n",
      "Customer_ID       0\n",
      "Customer_Name     0\n",
      "Segment           0\n",
      "Country           0\n",
      "City              0\n",
      "State             0\n",
      "Postal_Code      11\n",
      "Region            0\n",
      "Product_ID        0\n",
      "Category          0\n",
      "Sub-Category      0\n",
      "Product_Name      0\n",
      "Sales             0\n",
      "dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# See the first 5 rows to understand the structure\n",
    "print(\"First 5 Rows:\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Get a summary of the dataset (columns, data types, non-null values)\n",
    "print(\"DataFrame Info:\")\n",
    "df.info()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(\"Missing Values per Column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba39f5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Row_ID        Order_ID  Order_Date   Ship_Date       Ship_Mode  \\\n",
      "2234    2235  CA-2018-104066  05/12/2018  10/12/2018  Standard Class   \n",
      "5274    5275  CA-2016-162887  07/11/2016  09/11/2016    Second Class   \n",
      "8798    8799  US-2017-150140  06/04/2017  10/04/2017  Standard Class   \n",
      "9146    9147  US-2017-165505  23/01/2017  27/01/2017  Standard Class   \n",
      "9147    9148  US-2017-165505  23/01/2017  27/01/2017  Standard Class   \n",
      "9148    9149  US-2017-165505  23/01/2017  27/01/2017  Standard Class   \n",
      "9386    9387  US-2018-127292  19/01/2018  23/01/2018  Standard Class   \n",
      "9387    9388  US-2018-127292  19/01/2018  23/01/2018  Standard Class   \n",
      "9388    9389  US-2018-127292  19/01/2018  23/01/2018  Standard Class   \n",
      "9389    9390  US-2018-127292  19/01/2018  23/01/2018  Standard Class   \n",
      "9741    9742  CA-2016-117086  08/11/2016  12/11/2016  Standard Class   \n",
      "\n",
      "     Customer_ID     Customer_Name      Segment        Country        City  \\\n",
      "2234    QJ-19255      Quincy Jones    Corporate  United States  Burlington   \n",
      "5274    SV-20785  Stewart Visinsky     Consumer  United States  Burlington   \n",
      "8798    VM-21685   Valerie Mitchum  Home Office  United States  Burlington   \n",
      "9146    CB-12535  Claudia Bergmann    Corporate  United States  Burlington   \n",
      "9147    CB-12535  Claudia Bergmann    Corporate  United States  Burlington   \n",
      "9148    CB-12535  Claudia Bergmann    Corporate  United States  Burlington   \n",
      "9386    RM-19375     Raymond Messe     Consumer  United States  Burlington   \n",
      "9387    RM-19375     Raymond Messe     Consumer  United States  Burlington   \n",
      "9388    RM-19375     Raymond Messe     Consumer  United States  Burlington   \n",
      "9389    RM-19375     Raymond Messe     Consumer  United States  Burlington   \n",
      "9741    QJ-19255      Quincy Jones    Corporate  United States  Burlington   \n",
      "\n",
      "        State  Postal_Code Region       Product_ID         Category  \\\n",
      "2234  Vermont          NaN   East  TEC-AC-10001013       Technology   \n",
      "5274  Vermont          NaN   East  FUR-CH-10000595        Furniture   \n",
      "8798  Vermont          NaN   East  TEC-PH-10002555       Technology   \n",
      "9146  Vermont          NaN   East  TEC-AC-10002926       Technology   \n",
      "9147  Vermont          NaN   East  OFF-AR-10003477  Office Supplies   \n",
      "9148  Vermont          NaN   East  OFF-ST-10001526  Office Supplies   \n",
      "9386  Vermont          NaN   East  OFF-PA-10000157  Office Supplies   \n",
      "9387  Vermont          NaN   East  OFF-PA-10001970  Office Supplies   \n",
      "9388  Vermont          NaN   East  OFF-AP-10000828  Office Supplies   \n",
      "9389  Vermont          NaN   East  OFF-EN-10001509  Office Supplies   \n",
      "9741  Vermont          NaN   East  FUR-BO-10004834        Furniture   \n",
      "\n",
      "     Sub-Category                                       Product_Name    Sales  \n",
      "2234  Accessories        Logitech ClearChat Comfort/USB Headset H390   205.03  \n",
      "5274       Chairs                    Safco Contoured Stacking Chairs   715.20  \n",
      "8798       Phones                Nortel Meridian M5316 Digital phone  1294.75  \n",
      "9146  Accessories              Logitech Wireless Marathon Mouse M705    99.98  \n",
      "9147          Art                                  4009 Highlighters     8.04  \n",
      "9148      Storage              Iceberg Mobile Mega Data/Printer Cart  1564.29  \n",
      "9386        Paper                                          Xerox 191    79.92  \n",
      "9387        Paper                                         Xerox 1881    12.28  \n",
      "9388   Appliances                    Avanti 4.4 Cu. Ft. Refrigerator   542.94  \n",
      "9389    Envelopes                          Poly String Tie Envelopes     2.04  \n",
      "9741    Bookcases  Riverside Palais Royal Lawyers Bookcase, Royal...  4404.90  \n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame containing only the rows where Postal Code is null\n",
    "missing_postal_code_rows = df[df['Postal_Code'].isnull()]\n",
    "\n",
    "# Display these rows to see if we can find a pattern\n",
    "print(missing_postal_code_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692137a9",
   "metadata": {},
   "source": [
    "Based on a brief observation of the missing Postal Code values, we can see that all the missing postal codes are for the city of Burlington in the United States. This means, to handle the missing values, we simply need to replace the missing values with the correct primary postal code for Burlington which is: 05401.\n",
    "\n",
    "Burlington has a total of seven postal codes, of which, 05401 is considered the main postal code. However, this isn't an issue because our analysis will be at the state, regional, and city level and not a deep dive at the postal level. This means that even if we aren't 100% right, the impact of not having the exact postal code is negligable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edb02f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the correct postal code for Burlington, Vermont\n",
    "burlington_postal_code = 5401 # Use the number 5401, not the string '05401'\n",
    "\n",
    "# Use .loc to find rows where 'City' is 'Burlington' and fill the 'Postal Code'\n",
    "df.loc[df['City'] == 'Burlington', 'Postal_Code'] = df.loc[df['City'] == 'Burlington', 'Postal_Code'].fillna(burlington_postal_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3fbf234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values After Fix:\n",
      "Row_ID           0\n",
      "Order_ID         0\n",
      "Order_Date       0\n",
      "Ship_Date        0\n",
      "Ship_Mode        0\n",
      "Customer_ID      0\n",
      "Customer_Name    0\n",
      "Segment          0\n",
      "Country          0\n",
      "City             0\n",
      "State            0\n",
      "Postal_Code      0\n",
      "Region           0\n",
      "Product_ID       0\n",
      "Category         0\n",
      "Sub-Category     0\n",
      "Product_Name     0\n",
      "Sales            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify that there are no more missing values in the 'Postal Code' column\n",
    "print(\"Missing Values After Fix:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba478b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Order Date' and 'Ship Date' to datetime objects\n",
    "df['Order_Date'] = pd.to_datetime(df['Order_Date'], format='%d/%m/%Y')\n",
    "df['Ship_Date'] = pd.to_datetime(df['Ship_Date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b47eab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Order_Date  Ship_Date  Days_to_Ship\n",
      "0 2017-11-08 2017-11-11             3\n",
      "1 2017-11-08 2017-11-11             3\n",
      "2 2017-06-12 2017-06-16             4\n",
      "3 2016-10-11 2016-10-18             7\n",
      "4 2016-10-11 2016-10-18             7\n"
     ]
    }
   ],
   "source": [
    "# Creates 'Days to Ship'\n",
    "df['Days_to_Ship'] = (df['Ship_Date'] - df['Order_Date']).dt.days\n",
    "\n",
    "# Extracts 'Order Year' and 'Order Month Name'\n",
    "df['Order_Year'] = df['Order_Date'].dt.year\n",
    "df['Order_Month_Name'] = df['Order_Date'].dt.month_name()\n",
    "\n",
    "# Check the result\n",
    "print(df[['Order_Date', 'Ship_Date', 'Days_to_Ship']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0bb868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset created with the following columns:\n",
      "['Order_ID', 'Order_Date', 'Ship_Date', 'Ship_Mode', 'Customer_ID', 'Customer_Name', 'Segment', 'City', 'State', 'Postal_Code', 'Region', 'Product_ID', 'Product_Name', 'Category', 'Sub-Category', 'Sales', 'Days_to_Ship', 'Order_Year', 'Order_Month_Name']\n"
     ]
    }
   ],
   "source": [
    "# Define the columns we need to answer our business questions\n",
    "columns_to_keep = [\n",
    "    'Order_ID',\n",
    "    'Order_Date',\n",
    "    'Ship_Date',\n",
    "    'Ship_Mode',\n",
    "    'Customer_ID',\n",
    "    'Customer_Name',\n",
    "    'Segment',\n",
    "    'City',\n",
    "    'State',\n",
    "    'Postal_Code',\n",
    "    'Region',\n",
    "    'Product_ID',\n",
    "    \"Product_Name\",\n",
    "    'Category',\n",
    "    'Sub-Category',\n",
    "    'Sales',\n",
    "    'Days_to_Ship',\n",
    "    'Order_Year',\n",
    "    'Order_Month_Name'\n",
    "]\n",
    "\n",
    "# Create the final, lean DataFrame\n",
    "df_final = df[columns_to_keep]\n",
    "\n",
    "# Save the final DataFrame to CSV\n",
    "df_final.to_csv('cleaned_superstore_data.csv', index=False)\n",
    "\n",
    "print(\"\\nFinal dataset created with the following columns:\")\n",
    "print(df_final.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03f63cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_superstore_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21953802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows:\n",
      "         Order_ID  Order_Date   Ship_Date       Ship_Mode Customer_ID  \\\n",
      "0  CA-2017-152156  2017-11-08  2017-11-11    Second Class    CG-12520   \n",
      "1  CA-2017-152156  2017-11-08  2017-11-11    Second Class    CG-12520   \n",
      "2  CA-2017-138688  2017-06-12  2017-06-16    Second Class    DV-13045   \n",
      "3  US-2016-108966  2016-10-11  2016-10-18  Standard Class    SO-20335   \n",
      "4  US-2016-108966  2016-10-11  2016-10-18  Standard Class    SO-20335   \n",
      "\n",
      "     Customer_Name    Segment             City       State  Postal_Code  \\\n",
      "0      Claire Gute   Consumer        Henderson    Kentucky      42420.0   \n",
      "1      Claire Gute   Consumer        Henderson    Kentucky      42420.0   \n",
      "2  Darrin Van Huff  Corporate      Los Angeles  California      90036.0   \n",
      "3   Sean O'Donnell   Consumer  Fort Lauderdale     Florida      33311.0   \n",
      "4   Sean O'Donnell   Consumer  Fort Lauderdale     Florida      33311.0   \n",
      "\n",
      "  Region       Product_ID                                       Product_Name  \\\n",
      "0  South  FUR-BO-10001798                  Bush Somerset Collection Bookcase   \n",
      "1  South  FUR-CH-10000454  Hon Deluxe Fabric Upholstered Stacking Chairs,...   \n",
      "2   West  OFF-LA-10000240  Self-Adhesive Address Labels for Typewriters b...   \n",
      "3  South  FUR-TA-10000577      Bretford CR4500 Series Slim Rectangular Table   \n",
      "4  South  OFF-ST-10000760                     Eldon Fold 'N Roll Cart System   \n",
      "\n",
      "          Category Sub-Category     Sales  Days_to_Ship  Order_Year  \\\n",
      "0        Furniture    Bookcases  261.9600             3        2017   \n",
      "1        Furniture       Chairs  731.9400             3        2017   \n",
      "2  Office Supplies       Labels   14.6200             4        2017   \n",
      "3        Furniture       Tables  957.5775             7        2016   \n",
      "4  Office Supplies      Storage   22.3680             7        2016   \n",
      "\n",
      "  Order_Month_Name  \n",
      "0         November  \n",
      "1         November  \n",
      "2             June  \n",
      "3          October  \n",
      "4          October  \n",
      "\n",
      "==================================================\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9800 entries, 0 to 9799\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Order_ID          9800 non-null   object \n",
      " 1   Order_Date        9800 non-null   object \n",
      " 2   Ship_Date         9800 non-null   object \n",
      " 3   Ship_Mode         9800 non-null   object \n",
      " 4   Customer_ID       9800 non-null   object \n",
      " 5   Customer_Name     9800 non-null   object \n",
      " 6   Segment           9800 non-null   object \n",
      " 7   City              9800 non-null   object \n",
      " 8   State             9800 non-null   object \n",
      " 9   Postal_Code       9800 non-null   float64\n",
      " 10  Region            9800 non-null   object \n",
      " 11  Product_ID        9800 non-null   object \n",
      " 12  Product_Name      9800 non-null   object \n",
      " 13  Category          9800 non-null   object \n",
      " 14  Sub-Category      9800 non-null   object \n",
      " 15  Sales             9800 non-null   float64\n",
      " 16  Days_to_Ship      9800 non-null   int64  \n",
      " 17  Order_Year        9800 non-null   int64  \n",
      " 18  Order_Month_Name  9800 non-null   object \n",
      "dtypes: float64(2), int64(2), object(15)\n",
      "memory usage: 1.4+ MB\n",
      "\n",
      "==================================================\n",
      "\n",
      "Missing Values per Column:\n",
      "Order_ID            0\n",
      "Order_Date          0\n",
      "Ship_Date           0\n",
      "Ship_Mode           0\n",
      "Customer_ID         0\n",
      "Customer_Name       0\n",
      "Segment             0\n",
      "City                0\n",
      "State               0\n",
      "Postal_Code         0\n",
      "Region              0\n",
      "Product_ID          0\n",
      "Product_Name        0\n",
      "Category            0\n",
      "Sub-Category        0\n",
      "Sales               0\n",
      "Days_to_Ship        0\n",
      "Order_Year          0\n",
      "Order_Month_Name    0\n",
      "dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Number of duplicate rows: 1\n"
     ]
    }
   ],
   "source": [
    "# See the first 5 rows to understand the structure\n",
    "print(\"First 5 Rows:\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Get a summary of the dataset (columns, data types, non-null values)\n",
    "print(\"DataFrame Info:\")\n",
    "df.info()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(\"Missing Values per Column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606bf557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Consumer' 'Corporate' 'Home Office']\n",
      "  Customer Type  Total Customers\n",
      "0      Consumer             5101\n",
      "1     Corporate             2953\n",
      "2   Home Office             1746\n"
     ]
    }
   ],
   "source": [
    "#Customer Analaysis - Customer Segmentation\n",
    "\n",
    "#Types of customers\n",
    "Customer_types = df['Segment'].unique()\n",
    "print(Customer_types)\n",
    "\n",
    "#Amount of each customer type\n",
    "number_of_customers = df['Segment'].value_counts().reset_index()\n",
    "\n",
    "number_of_customers = number_of_customers.rename(columns={'Segment' : 'Customer Type', 'count': 'Total Customers'})\n",
    "\n",
    "print(number_of_customers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
